{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Importing Spark libraries\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, min, max, avg, count\n",
    "\n",
    "# Importing Python Data Stat. libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# For error handling and utilities \n",
    "import json\n",
    "import requests\n",
    "import urllib.request\n",
    "import sys\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/11 18:33:58 WARN Utils: Your hostname, codespaces-358acb resolves to a loopback address: 127.0.0.1; using 10.0.13.105 instead (on interface eth0)\n",
      "24/10/11 18:33:58 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/10/11 18:33:59 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/10/11 18:34:00 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "# Spark builder (check warnings - port 4041)\n",
    "spark = SparkSession.builder.appName(\"AirportFlightDataViz\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adsb.json data successfully loaded\n",
      "data_adsb {'AircraftId': '400960', 'Latitude': 10.81889, 'Longitude': 106.65194, 'Track': 30, 'Altitude': 0, 'Speed': 0, 'Squawk': 7713, 'Type': 'A320', 'Registration': 'G-TTOE', 'LastUpdate': 1696278420, 'Origin': 'SGN', 'Destination': 'ICN', 'Flight': 'BA484', 'Onground': 1, 'Vspeed': 0, 'Callsign': 'BAW476C', 'SourceType': 'ADS-B FR24 receivers', 'ETA': 0}\n",
      "data_adsb {'AircraftId': '400960', 'Latitude': 12.5, 'Longitude': 109.1, 'Track': 45, 'Altitude': 10000, 'Speed': 300, 'Squawk': 7713, 'Type': 'A320', 'Registration': 'G-TTOE', 'LastUpdate': 1696279020, 'Origin': 'SGN', 'Destination': 'ICN', 'Flight': 'BA484', 'Onground': 0, 'Vspeed': 1500, 'Callsign': 'BAW476C', 'SourceType': 'ADS-B FR24 receivers', 'ETA': 0}\n",
      "file_absd.json exist\n"
     ]
    }
   ],
   "source": [
    "url_adsb = \"https://raw.githubusercontent.com/JM-AE/Airport-Flight-Data/refs/heads/main/adsb.json\"\n",
    "response_adsb = requests.get(url_adsb)\n",
    "\n",
    "# Check if file is possible to load using py.json\n",
    "if response_adsb.status_code == 200:\n",
    "    data_adsb = response_adsb.json()\n",
    "    print(\"adsb.json data successfully loaded\")\n",
    "else: print(f\"Failed to load adsb.json Status code:{response_adsb.status_code}\")\n",
    "\n",
    "# Print sample of .json file\n",
    "for entry_adsb in data_adsb[:2]:\n",
    "    print(\"data_adsb\",entry_adsb)\n",
    "\n",
    "# Request save as tmp file \n",
    "urllib.request.urlretrieve(url_adsb,\"/tmp/file_absd.json\")\n",
    "\n",
    "# Check if file exist on correct address\n",
    "if os.path.exists(\"/tmp/file_absd.json\"):\n",
    "    print(\"tmp file_absd.json exist\")\n",
    "else: \n",
    "    print(\"tmp file_absd.json do not exist\")\n",
    "\n",
    "# Check if .joson valid or not\n",
    "with open(\"/tmp/file_absd.json\",\"r\") as f:\n",
    "    try:\n",
    "       data_adsb = json.lo \n",
    "\n",
    "# Load in to Spark DF with check for error     \n",
    "try:\n",
    "    df_absd =spark.read.json(\"/tmp/file_absd.json\")\n",
    "    df_absd.show(3)\n",
    "except Exception as e:\n",
    "    print(f\"Error loading DataFrame:{str(e)}\")\n",
    "\n",
    "df_absd.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adsb_multi.json data successfully loaded\n"
     ]
    }
   ],
   "source": [
    "url_adsb_multi = \"https://raw.githubusercontent.com/JM-AE/Airport-Flight-Data/refs/heads/main/adsb_multi_aircraft.json\"\n",
    "response_adsb_multi = requests.get(url_adsb_multi)\n",
    "\n",
    "if response_adsb_multi.status_code == 200:\n",
    "    data_adsb_multi = response_adsb_multi.json()\n",
    "    print(\"adsb_multi.json data successfully loaded\")\n",
    "else: print(f\"Failed to load adsb_multi.json Status code:{response_adsb_multi.status_code}\")\n",
    "\n",
    "urllib.request.urlretrieve(url_adsb_multi,\"/tmp/file_absd_multi.json\")\n",
    "df_absd_multi =spark.read.json(\"/tmp/file_absd_multi.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_adsb {'AircraftId': '400960', 'Latitude': 10.81889, 'Longitude': 106.65194, 'Track': 30, 'Altitude': 0, 'Speed': 0, 'Squawk': 7713, 'Type': 'A320', 'Registration': 'G-TTOE', 'LastUpdate': 1696278420, 'Origin': 'SGN', 'Destination': 'ICN', 'Flight': 'BA484', 'Onground': 1, 'Vspeed': 0, 'Callsign': 'BAW476C', 'SourceType': 'ADS-B FR24 receivers', 'ETA': 0}\n",
      "data_adsb {'AircraftId': '400960', 'Latitude': 12.5, 'Longitude': 109.1, 'Track': 45, 'Altitude': 10000, 'Speed': 300, 'Squawk': 7713, 'Type': 'A320', 'Registration': 'G-TTOE', 'LastUpdate': 1696279020, 'Origin': 'SGN', 'Destination': 'ICN', 'Flight': 'BA484', 'Onground': 0, 'Vspeed': 1500, 'Callsign': 'BAW476C', 'SourceType': 'ADS-B FR24 receivers', 'ETA': 0}\n",
      "data_adsb {'AircraftId': '400960', 'Latitude': 15.3, 'Longitude': 113.5, 'Track': 50, 'Altitude': 30000, 'Speed': 500, 'Squawk': 7713, 'Type': 'A320', 'Registration': 'G-TTOE', 'LastUpdate': 1696280020, 'Origin': 'SGN', 'Destination': 'ICN', 'Flight': 'BA484', 'Onground': 0, 'Vspeed': 2000, 'Callsign': 'BAW476C', 'SourceType': 'ADS-B FR24 receivers', 'ETA': 0}\n",
      "data_adsb_multi {'AircraftId': '400960', 'Latitude': 10.81889, 'Longitude': 106.65194, 'Track': 30, 'Altitude': 0, 'Speed': 0, 'Squawk': 7713, 'Type': 'A320', 'Registration': 'G-TTOE', 'LastUpdate': 1696278420, 'Origin': 'SGN', 'Destination': 'ICN', 'Flight': 'BA484', 'Onground': 1, 'Vspeed': 0, 'Callsign': 'BAW476C', 'SourceType': 'ADS-B FR24 receivers', 'ETA': 0}\n",
      "data_adsb_multi {'AircraftId': '400960', 'Latitude': 12.5, 'Longitude': 109.1, 'Track': 45, 'Altitude': 10000, 'Speed': 300, 'Squawk': 7713, 'Type': 'A320', 'Registration': 'G-TTOE', 'LastUpdate': 1696279020, 'Origin': 'SGN', 'Destination': 'ICN', 'Flight': 'BA484', 'Onground': 0, 'Vspeed': 1500, 'Callsign': 'BAW476C', 'SourceType': 'ADS-B FR24 receivers', 'ETA': 0}\n",
      "data_adsb_multi {'AircraftId': '400960', 'Latitude': 15.3, 'Longitude': 113.5, 'Track': 50, 'Altitude': 30000, 'Speed': 500, 'Squawk': 7713, 'Type': 'A320', 'Registration': 'G-TTOE', 'LastUpdate': 1696280020, 'Origin': 'SGN', 'Destination': 'ICN', 'Flight': 'BA484', 'Onground': 0, 'Vspeed': 2000, 'Callsign': 'BAW476C', 'SourceType': 'ADS-B FR24 receivers', 'ETA': 0}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for entry_adsb_multi in data_adsb_multi[:3]:\n",
    "    print(\"data_adsb_multi\",entry_adsb_multi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading DataFrame:Since Spark 2.3, the queries from raw JSON/CSV files are disallowed when the\n",
      "referenced columns only include the internal corrupt record column\n",
      "(named _corrupt_record by default). For example:\n",
      "spark.read.schema(schema).csv(file).filter($\"_corrupt_record\".isNotNull).count()\n",
      "and spark.read.schema(schema).csv(file).select(\"_corrupt_record\").show().\n",
      "Instead, you can cache or save the parsed results and then send the same query.\n",
      "For example, val df = spark.read.schema(schema).csv(file).cache() and then\n",
      "df.filter($\"_corrupt_record\".isNotNull).count().\n",
      "root\n",
      " |-- _corrupt_record: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    df_absd =spark.read.json(\"/tmp/file_absd.json\")\n",
    "    df_absd.show(3)\n",
    "except Exception as e:\n",
    "    print(f\"Error loading DataFrame:{str(e)}\")\n",
    "\n",
    "df_absd.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
