{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a119987-bcbe-4c4d-8684-a4d06e58c82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Spark libs.\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import min, max, avg, count, expr, array_contains, col, explode_outer, explode, struct\n",
    "from pyspark.sql import DataFrame, functions as F\n",
    "from pyspark.sql import types as T\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.types import ArrayType, StructType, StringType, DoubleType, TimestampType\n",
    "\n",
    "# Importing Python Data Stat. and vis. libs.\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# For error handling and utilities \n",
    "import json\n",
    "import requests\n",
    "import urllib.request\n",
    "from io import StringIO\n",
    "from urllib.parse import urlparse\n",
    "import sys\n",
    "import os\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3fdf817-0cc6-4dd3-8cc2-76a255874c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_oag = \"https://raw.githubusercontent.com/JM-AE/Airport-Flight-Data/refs/heads/main/oag.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "caf2abf0-7ece-4e9e-9ab2-526944000506",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/14 22:33:10 WARN Utils: Your hostname, codespaces-358acb resolves to a loopback address: 127.0.0.1; using 10.0.1.36 instead (on interface eth0)\n",
      "24/10/14 22:33:10 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/10/14 22:33:11 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/10/14 22:33:12 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "24/10/14 22:33:31 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.master(\"local[*]\").appName(\"AirportFlightDataViz\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8349f13-cf42-48d6-bc88-75b1f30476d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "1. Load a dataset simulating airport and flight data - adsb.json, oag.json files.\n",
    "General functions to download data from URL and load it into a Spark DataFrame.\n",
    "\"\"\"\n",
    "\n",
    "def load_data(url):\n",
    "    \"\"\"Load data from a given URL into a Spark DataFrame.\"\"\"\n",
    "    \n",
    "    # Step 1: Extract the file name from the URL\n",
    "    file_name = os.path.basename(urlparse(url).path)\n",
    "    \n",
    "    # Step 2: Download the data\n",
    "    data = stream_download(url)\n",
    "    if data is None:\n",
    "        return None  \n",
    "\n",
    "    # Step 3: Analyze the structure (optional)\n",
    "    analyze_json_structure(data)\n",
    "    \n",
    "    # Step 4: Try loading into Spark without saving to disk\n",
    "    try:\n",
    "        df = load_spark_dataframe_from_memory(data)\n",
    "        print(\"#4# DataFrame loaded successfully from memory #4#\")\n",
    "    except Exception as e:\n",
    "        print(f\"#4# Error loading DataFrame from memory: {str(e)} #4#\")\n",
    "        print(\"#4# Attempting to load DataFrame using file-based approach #4#\")\n",
    "\n",
    "        # Step 4.1: Fallback: Save to a temporary file and read into Spark\n",
    "        tmp_file_path = save_to_temp_file(data, file_name)\n",
    "        if tmp_file_path is None:\n",
    "            return None\n",
    "\n",
    "        # Step 4.2: Validate and load the DataFrame from the file\n",
    "        df = load_spark_dataframe(tmp_file_path)\n",
    "        if df is None:\n",
    "            return None  \n",
    "    \n",
    "    # Step 5: Show the DataFrame\n",
    "    print(\"#5# DataFrame 1st line #5#\")\n",
    "    df.show(1)\n",
    "    return df\n",
    "\n",
    "def stream_download(url):\n",
    "    \"\"\"Download data from the URL and return it as a string (JSON).\"\"\"\n",
    "    try:\n",
    "        response = requests.get(url, stream=True)\n",
    "        if response.status_code == 200:\n",
    "            print(f\"#1# Data from {url} successfully loaded #1#\")\n",
    "            return response.text  # Return the raw JSON data as a string\n",
    "        else:\n",
    "            print(f\"#1# Failed to load {url}. Status code: {response.status_code} #1#\")\n",
    "            return None\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"#1# Error while downloading data from {url}: {str(e)} #1#\")\n",
    "        return None\n",
    "\n",
    "def analyze_json_structure(data):\n",
    "    \"\"\"Analyze the structure of the JSON data and print a sample.\"\"\"\n",
    "    try:\n",
    "        json_data = json.loads(data)\n",
    "        if isinstance(json_data, dict):\n",
    "            keys = list(json_data.keys())\n",
    "            print(f\"#2# Top-level keys found: {keys} #2#\")\n",
    "        elif isinstance(json_data, list):\n",
    "            print(f\"#2# Sample data from the list: {json.dumps(json_data[:1], indent=4)} #2#\")\n",
    "        else:\n",
    "            print(\"#2# No valid data structure found. #2#\")\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"#2# Failed to parse JSON structure. Skipping analysis. #2#\")\n",
    "\n",
    "def save_to_temp_file(data, file_name):\n",
    "    \"\"\"Save the JSON string to a temporary file and return the file path.\"\"\"\n",
    "    try:\n",
    "        tmp_file_path = os.path.join(tempfile.gettempdir(), file_name)\n",
    "        with open(tmp_file_path, \"w\") as f:\n",
    "            f.write(data)\n",
    "        print(f\"#3# Temporary file {file_name} saved #3#\")\n",
    "        return tmp_file_path\n",
    "    except Exception as e:\n",
    "        print(f\"#3# Error saving temporary file {file_name}: {str(e)} #3#\")\n",
    "        return None\n",
    "\n",
    "def load_spark_dataframe_from_memory(data):\n",
    "    \"\"\"Load the JSON data into a Spark DataFrame from an in-memory string.\"\"\"\n",
    "    try:\n",
    "        json_rdd = spark.sparkContext.parallelize([data])\n",
    "        df = spark.read.json(json_rdd)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"#4# Error loading DataFrame from memory: {str(e)} #4#\")\n",
    "        raise\n",
    "\n",
    "def load_spark_dataframe(file_path):\n",
    "    \"\"\"Load the JSON data from a file into a Spark DataFrame with error handling.\"\"\"\n",
    "    try:\n",
    "        df = spark.read.json(file_path)\n",
    "        print(\"#4# DataFrame loaded successfully from file #4#\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"#4# Error loading DataFrame from file: {str(e)} #4#\")\n",
    "        print(\"#4# Attempting to load DataFrame using multiline option #4#\")\n",
    "        \n",
    "        try:\n",
    "            df = spark.read.option(\"multiline\", \"true\").json(file_path)\n",
    "            print(\"#4# DataFrame loaded successfully in multiline option #4#\")\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            print(f\"#4# Error loading DataFrame in multiline option: {str(e)} #4#\")\n",
    "            return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4546a35-37c6-4efe-9773-5f41a174520e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#1# Data from https://raw.githubusercontent.com/JM-AE/Airport-Flight-Data/refs/heads/main/oag.json successfully loaded #1#\n",
      "#2# Top-level keys found: ['data', 'paging'] #2#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#4# DataFrame loaded successfully from memory #4#\n",
      "#5# DataFrame 1st line #5#\n",
      "+--------------------+--------------------+\n",
      "|                data|              paging|\n",
      "+--------------------+--------------------+\n",
      "|[{{773, NULL}, {{...|{10, https://api....|\n",
      "+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_oag = load_data(url_oag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8adae19-149a-439c-9ea2-b711d4135aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_json(df):\n",
    "    \"\"\"Flatten a DataFrame with nested structures into a 2D structure.\"\"\"\n",
    "    \n",
    "    # Compute Complex Fields in Schema   \n",
    "    complex_fields = dict([(field.name, field.dataType)\n",
    "                           for field in df.schema.fields\n",
    "                           if isinstance(field.dataType, (T.ArrayType, T.StructType))])\n",
    "\n",
    "    counter = 1  \n",
    "\n",
    "    while complex_fields:\n",
    "        col_name = list(complex_fields.keys())[0]\n",
    "        print(f\"{counter}: {col_name} of type {type(complex_fields[col_name])}\")\n",
    "        counter += 1  \n",
    "\n",
    "        # If StructType, convert all sub-elements to columns.\n",
    "        if isinstance(complex_fields[col_name], T.StructType):\n",
    "            expanded = [F.col(col_name + '.' + k).alias(col_name + '_' + k) \n",
    "                        for k in [n.name for n in complex_fields[col_name]]]\n",
    "            df = df.select(\"*\", *expanded).drop(col_name)\n",
    "\n",
    "        # If ArrayType, add the array elements as rows us the explode function    \n",
    "        elif isinstance(complex_fields[col_name], T.ArrayType):    \n",
    "            df = df.withColumn(col_name, explode_outer(col_name))\n",
    "\n",
    "        # Recompute remaining complex fields in schema       \n",
    "        complex_fields = dict([(field.name, field.dataType)\n",
    "                               for field in df.schema.fields\n",
    "                               if isinstance(field.dataType, (T.ArrayType, T.StructType))])\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d2cbe395-4fa8-4fb4-a44f-bdc0c0d744bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: data of type <class 'pyspark.sql.types.ArrayType'>\n",
      "2: data of type <class 'pyspark.sql.types.StructType'>\n",
      "3: data_aircraftType of type <class 'pyspark.sql.types.StructType'>\n",
      "4: data_arrival of type <class 'pyspark.sql.types.StructType'>\n",
      "5: data_carrier of type <class 'pyspark.sql.types.StructType'>\n",
      "6: data_codeshare of type <class 'pyspark.sql.types.StructType'>\n",
      "7: data_departure of type <class 'pyspark.sql.types.StructType'>\n",
      "8: data_segmentInfo of type <class 'pyspark.sql.types.StructType'>\n",
      "9: data_serviceType of type <class 'pyspark.sql.types.StructType'>\n",
      "10: data_statusDetails of type <class 'pyspark.sql.types.ArrayType'>\n",
      "11: data_statusDetails of type <class 'pyspark.sql.types.StructType'>\n",
      "12: data_arrival_airport of type <class 'pyspark.sql.types.StructType'>\n",
      "13: data_arrival_date of type <class 'pyspark.sql.types.StructType'>\n",
      "14: data_arrival_time of type <class 'pyspark.sql.types.StructType'>\n",
      "15: data_codeshare_aircraftOwner of type <class 'pyspark.sql.types.StructType'>\n",
      "16: data_codeshare_cockpitCrewEmployer of type <class 'pyspark.sql.types.StructType'>\n",
      "17: data_codeshare_jointOperationAirlineDesignators of type <class 'pyspark.sql.types.ArrayType'>\n",
      "18: data_codeshare_marketingFlights of type <class 'pyspark.sql.types.ArrayType'>\n",
      "19: data_codeshare_marketingFlights of type <class 'pyspark.sql.types.StructType'>\n",
      "20: data_departure_airport of type <class 'pyspark.sql.types.StructType'>\n",
      "21: data_departure_date of type <class 'pyspark.sql.types.StructType'>\n",
      "22: data_departure_time of type <class 'pyspark.sql.types.StructType'>\n",
      "23: data_segmentInfo_intermediateAirports of type <class 'pyspark.sql.types.StructType'>\n",
      "24: data_statusDetails_arrival of type <class 'pyspark.sql.types.StructType'>\n",
      "25: data_statusDetails_departure of type <class 'pyspark.sql.types.StructType'>\n",
      "26: data_statusDetails_equipment of type <class 'pyspark.sql.types.StructType'>\n",
      "27: data_segmentInfo_intermediateAirports_iata of type <class 'pyspark.sql.types.ArrayType'>\n",
      "28: data_statusDetails_arrival_actualTime of type <class 'pyspark.sql.types.StructType'>\n",
      "29: data_statusDetails_arrival_airport of type <class 'pyspark.sql.types.StructType'>\n",
      "30: data_statusDetails_arrival_estimatedTime of type <class 'pyspark.sql.types.StructType'>\n",
      "31: data_statusDetails_departure_actualTime of type <class 'pyspark.sql.types.StructType'>\n",
      "32: data_statusDetails_departure_airport of type <class 'pyspark.sql.types.StructType'>\n",
      "33: data_statusDetails_departure_estimatedTime of type <class 'pyspark.sql.types.StructType'>\n",
      "34: data_statusDetails_equipment_actualAircraftType of type <class 'pyspark.sql.types.StructType'>\n",
      "35: data_statusDetails_arrival_actualTime_inGate of type <class 'pyspark.sql.types.StructType'>\n",
      "36: data_statusDetails_arrival_actualTime_onGround of type <class 'pyspark.sql.types.StructType'>\n",
      "37: data_statusDetails_arrival_estimatedTime_inGate of type <class 'pyspark.sql.types.StructType'>\n",
      "38: data_statusDetails_arrival_estimatedTime_onGround of type <class 'pyspark.sql.types.StructType'>\n",
      "39: data_statusDetails_departure_actualTime_offGround of type <class 'pyspark.sql.types.StructType'>\n",
      "40: data_statusDetails_departure_actualTime_outGate of type <class 'pyspark.sql.types.StructType'>\n",
      "41: data_statusDetails_departure_estimatedTime_offGround of type <class 'pyspark.sql.types.StructType'>\n",
      "42: data_statusDetails_departure_estimatedTime_outGate of type <class 'pyspark.sql.types.StructType'>\n"
     ]
    }
   ],
   "source": [
    "df_oag_d = df_oag.drop(\"paging\")\n",
    "dft1 = flatten_json(df_oag_d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "70546168-650e-48b6-a882-078ae6e5110c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dftd = dft1.dropDuplicates([\"data_statusKey\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6843dfb4-8447-49c7-8736-f8f1c80908c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/14 22:46:33 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "[Stage 3:=============================>                             (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 80)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data_elapsedTime</th>\n",
       "      <th>data_flightNumber</th>\n",
       "      <th>data_flightType</th>\n",
       "      <th>data_scheduleInstanceKey</th>\n",
       "      <th>data_sequenceNumber</th>\n",
       "      <th>data_serviceSuffix</th>\n",
       "      <th>data_statusKey</th>\n",
       "      <th>data_aircraftType_iata</th>\n",
       "      <th>data_aircraftType_icao</th>\n",
       "      <th>data_arrival_terminal</th>\n",
       "      <th>...</th>\n",
       "      <th>data_statusDetails_arrival_estimatedTime_onGround_local</th>\n",
       "      <th>data_statusDetails_arrival_estimatedTime_onGround_utc</th>\n",
       "      <th>data_statusDetails_departure_actualTime_offGround_local</th>\n",
       "      <th>data_statusDetails_departure_actualTime_offGround_utc</th>\n",
       "      <th>data_statusDetails_departure_actualTime_outGate_local</th>\n",
       "      <th>data_statusDetails_departure_actualTime_outGate_utc</th>\n",
       "      <th>data_statusDetails_departure_estimatedTime_offGround_local</th>\n",
       "      <th>data_statusDetails_departure_estimatedTime_offGround_utc</th>\n",
       "      <th>data_statusDetails_departure_estimatedTime_outGate_local</th>\n",
       "      <th>data_statusDetails_departure_estimatedTime_outGate_utc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>245</td>\n",
       "      <td>476</td>\n",
       "      <td>Scheduled</td>\n",
       "      <td>f769ad9943f71eaf190e39107f85815aa4bf3440961f20...</td>\n",
       "      <td>1.0</td>\n",
       "      <td></td>\n",
       "      <td>224b0ebdf6f19879160010c86435ebf0ae6d42a05f62b6...</td>\n",
       "      <td>7M8</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2023-10-03T11:39:00-04:00</td>\n",
       "      <td>2023-10-03T15:39:00+00:00</td>\n",
       "      <td>2023-10-03T08:12:00-04:00</td>\n",
       "      <td>2023-10-03T12:12:00+00:00</td>\n",
       "      <td>2023-10-03T07:54:00-04:00</td>\n",
       "      <td>2023-10-03T11:54:00+00:00</td>\n",
       "      <td>2023-10-03T08:15:00-04:00</td>\n",
       "      <td>2023-10-03T12:15:00+00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>476</td>\n",
       "      <td>Unscheduled</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>2dabdd879800b7f30b3f3eef8c2f56dbae24eb542399b9...</td>\n",
       "      <td>None</td>\n",
       "      <td>E545</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-10-03T08:37:00-04:00</td>\n",
       "      <td>2023-10-03T12:37:00+00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>167</td>\n",
       "      <td>476</td>\n",
       "      <td>Scheduled</td>\n",
       "      <td>c0dd7369dd3e81cdccad73b23c5df35c68ad3a99f4ae6c...</td>\n",
       "      <td>1.0</td>\n",
       "      <td></td>\n",
       "      <td>3d7496b198a37b5401841876ac9eabdacfa065f316417d...</td>\n",
       "      <td>738</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-10-03T06:12:00-06:00</td>\n",
       "      <td>2023-10-03T12:12:00+00:00</td>\n",
       "      <td>2023-10-03T05:54:00-06:00</td>\n",
       "      <td>2023-10-03T11:54:00+00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-10-03T06:03:00-06:00</td>\n",
       "      <td>2023-10-03T12:03:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90</td>\n",
       "      <td>476</td>\n",
       "      <td>Scheduled</td>\n",
       "      <td>64cf9c774e3c3fb4a41b4486fd8c9a98b6d82480c8c28d...</td>\n",
       "      <td>1.0</td>\n",
       "      <td></td>\n",
       "      <td>55a23dce3c3aa9976b6c70ce1554a88e075d64380c6891...</td>\n",
       "      <td>320</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>2023-10-03T04:06:00+03:30</td>\n",
       "      <td>2023-10-03T00:36:00+00:00</td>\n",
       "      <td>2023-10-03T02:41:00+03:00</td>\n",
       "      <td>2023-10-02T23:41:00+00:00</td>\n",
       "      <td>2023-10-03T02:04:00+03:00</td>\n",
       "      <td>2023-10-02T23:04:00+00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-10-03T01:45:00+03:00</td>\n",
       "      <td>2023-10-02T22:45:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>476</td>\n",
       "      <td>Unscheduled</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>9e34394abe83142c5a8000197516822dc32bad97ea81ae...</td>\n",
       "      <td>None</td>\n",
       "      <td>B763</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-10-03T05:09:00-04:00</td>\n",
       "      <td>2023-10-03T09:09:00+00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>305</td>\n",
       "      <td>476</td>\n",
       "      <td>Scheduled</td>\n",
       "      <td>42fe92775283678d9221e60ba329ebe745c537164255f0...</td>\n",
       "      <td>1.0</td>\n",
       "      <td></td>\n",
       "      <td>ad7e703e763f73a7c5f807140755e8626ebba7f7604641...</td>\n",
       "      <td>773</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2023-10-03T07:15:00+09:00</td>\n",
       "      <td>2023-10-02T22:15:00+00:00</td>\n",
       "      <td>2023-10-03T00:43:00+07:00</td>\n",
       "      <td>2023-10-02T17:43:00+00:00</td>\n",
       "      <td>2023-10-03T00:31:00+07:00</td>\n",
       "      <td>2023-10-02T17:31:00+00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-10-03T00:15:00+07:00</td>\n",
       "      <td>2023-10-02T17:15:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>75</td>\n",
       "      <td>476</td>\n",
       "      <td>Scheduled</td>\n",
       "      <td>98693425486c83d73e79d610fea00b1dcda072e3131bab...</td>\n",
       "      <td>1.0</td>\n",
       "      <td></td>\n",
       "      <td>af89e25495692a0bcd5e742c5239c71b6e74985bd3ef93...</td>\n",
       "      <td>73H</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-10-03T09:56:00+09:00</td>\n",
       "      <td>2023-10-03T00:56:00+00:00</td>\n",
       "      <td>2023-10-03T09:46:00+09:00</td>\n",
       "      <td>2023-10-03T00:46:00+00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-10-03T09:45:00+09:00</td>\n",
       "      <td>2023-10-03T00:45:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>200</td>\n",
       "      <td>476</td>\n",
       "      <td>Scheduled</td>\n",
       "      <td>3c2fe081f722793ccab3d630a942bf39c2703716101c76...</td>\n",
       "      <td>1.0</td>\n",
       "      <td></td>\n",
       "      <td>c1bbb6b086a6d38a0a97c39ae177ddb512719bf1e6e4f3...</td>\n",
       "      <td>320</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-10-03T08:57:00+01:00</td>\n",
       "      <td>2023-10-03T07:57:00+00:00</td>\n",
       "      <td>2023-10-03T08:38:00+01:00</td>\n",
       "      <td>2023-10-03T07:38:00+00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-10-03T08:31:00+01:00</td>\n",
       "      <td>2023-10-03T07:31:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>476</td>\n",
       "      <td>Unscheduled</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>c28e5c5bffc8a86d3a1aae702915ca39899e91d2ee131d...</td>\n",
       "      <td>None</td>\n",
       "      <td>B763</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-10-03T07:40:00-04:00</td>\n",
       "      <td>2023-10-03T11:40:00+00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>135</td>\n",
       "      <td>476</td>\n",
       "      <td>Scheduled</td>\n",
       "      <td>8e70c0c3d665cc249a70f27ca2efddccf5c904520873b7...</td>\n",
       "      <td>1.0</td>\n",
       "      <td></td>\n",
       "      <td>fa3e07f019fe3dd03dc7ba02aac85bc874d023179f58fd...</td>\n",
       "      <td>320</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-10-03T08:26:00+01:00</td>\n",
       "      <td>2023-10-03T07:26:00+00:00</td>\n",
       "      <td>2023-10-03T08:11:00+01:00</td>\n",
       "      <td>2023-10-03T07:11:00+00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-10-03T08:05:00+01:00</td>\n",
       "      <td>2023-10-03T07:05:00+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   data_elapsedTime  data_flightNumber data_flightType  \\\n",
       "0               245                476       Scheduled   \n",
       "1                 0                476     Unscheduled   \n",
       "2               167                476       Scheduled   \n",
       "3                90                476       Scheduled   \n",
       "4                 0                476     Unscheduled   \n",
       "5               305                476       Scheduled   \n",
       "6                75                476       Scheduled   \n",
       "7               200                476       Scheduled   \n",
       "8                 0                476     Unscheduled   \n",
       "9               135                476       Scheduled   \n",
       "\n",
       "                            data_scheduleInstanceKey  data_sequenceNumber  \\\n",
       "0  f769ad9943f71eaf190e39107f85815aa4bf3440961f20...                  1.0   \n",
       "1                                               None                  NaN   \n",
       "2  c0dd7369dd3e81cdccad73b23c5df35c68ad3a99f4ae6c...                  1.0   \n",
       "3  64cf9c774e3c3fb4a41b4486fd8c9a98b6d82480c8c28d...                  1.0   \n",
       "4                                               None                  NaN   \n",
       "5  42fe92775283678d9221e60ba329ebe745c537164255f0...                  1.0   \n",
       "6  98693425486c83d73e79d610fea00b1dcda072e3131bab...                  1.0   \n",
       "7  3c2fe081f722793ccab3d630a942bf39c2703716101c76...                  1.0   \n",
       "8                                               None                  NaN   \n",
       "9  8e70c0c3d665cc249a70f27ca2efddccf5c904520873b7...                  1.0   \n",
       "\n",
       "  data_serviceSuffix                                     data_statusKey  \\\n",
       "0                     224b0ebdf6f19879160010c86435ebf0ae6d42a05f62b6...   \n",
       "1               None  2dabdd879800b7f30b3f3eef8c2f56dbae24eb542399b9...   \n",
       "2                     3d7496b198a37b5401841876ac9eabdacfa065f316417d...   \n",
       "3                     55a23dce3c3aa9976b6c70ce1554a88e075d64380c6891...   \n",
       "4               None  9e34394abe83142c5a8000197516822dc32bad97ea81ae...   \n",
       "5                     ad7e703e763f73a7c5f807140755e8626ebba7f7604641...   \n",
       "6                     af89e25495692a0bcd5e742c5239c71b6e74985bd3ef93...   \n",
       "7                     c1bbb6b086a6d38a0a97c39ae177ddb512719bf1e6e4f3...   \n",
       "8               None  c28e5c5bffc8a86d3a1aae702915ca39899e91d2ee131d...   \n",
       "9                     fa3e07f019fe3dd03dc7ba02aac85bc874d023179f58fd...   \n",
       "\n",
       "  data_aircraftType_iata data_aircraftType_icao data_arrival_terminal  ...  \\\n",
       "0                    7M8                   None                     3  ...   \n",
       "1                   None                   E545                  None  ...   \n",
       "2                    738                   None                        ...   \n",
       "3                    320                   None                        ...   \n",
       "4                   None                   B763                  None  ...   \n",
       "5                    773                   None                     2  ...   \n",
       "6                    73H                   None                     1  ...   \n",
       "7                    320                   None                        ...   \n",
       "8                   None                   B763                  None  ...   \n",
       "9                    320                   None                     1  ...   \n",
       "\n",
       "  data_statusDetails_arrival_estimatedTime_onGround_local  \\\n",
       "0                          2023-10-03T11:39:00-04:00        \n",
       "1                                               None        \n",
       "2                                               None        \n",
       "3                          2023-10-03T04:06:00+03:30        \n",
       "4                                               None        \n",
       "5                          2023-10-03T07:15:00+09:00        \n",
       "6                                               None        \n",
       "7                                               None        \n",
       "8                                               None        \n",
       "9                                               None        \n",
       "\n",
       "  data_statusDetails_arrival_estimatedTime_onGround_utc  \\\n",
       "0                          2023-10-03T15:39:00+00:00      \n",
       "1                                               None      \n",
       "2                                               None      \n",
       "3                          2023-10-03T00:36:00+00:00      \n",
       "4                                               None      \n",
       "5                          2023-10-02T22:15:00+00:00      \n",
       "6                                               None      \n",
       "7                                               None      \n",
       "8                                               None      \n",
       "9                                               None      \n",
       "\n",
       "  data_statusDetails_departure_actualTime_offGround_local  \\\n",
       "0                          2023-10-03T08:12:00-04:00        \n",
       "1                          2023-10-03T08:37:00-04:00        \n",
       "2                          2023-10-03T06:12:00-06:00        \n",
       "3                          2023-10-03T02:41:00+03:00        \n",
       "4                          2023-10-03T05:09:00-04:00        \n",
       "5                          2023-10-03T00:43:00+07:00        \n",
       "6                          2023-10-03T09:56:00+09:00        \n",
       "7                          2023-10-03T08:57:00+01:00        \n",
       "8                          2023-10-03T07:40:00-04:00        \n",
       "9                          2023-10-03T08:26:00+01:00        \n",
       "\n",
       "  data_statusDetails_departure_actualTime_offGround_utc  \\\n",
       "0                          2023-10-03T12:12:00+00:00      \n",
       "1                          2023-10-03T12:37:00+00:00      \n",
       "2                          2023-10-03T12:12:00+00:00      \n",
       "3                          2023-10-02T23:41:00+00:00      \n",
       "4                          2023-10-03T09:09:00+00:00      \n",
       "5                          2023-10-02T17:43:00+00:00      \n",
       "6                          2023-10-03T00:56:00+00:00      \n",
       "7                          2023-10-03T07:57:00+00:00      \n",
       "8                          2023-10-03T11:40:00+00:00      \n",
       "9                          2023-10-03T07:26:00+00:00      \n",
       "\n",
       "   data_statusDetails_departure_actualTime_outGate_local  \\\n",
       "0                          2023-10-03T07:54:00-04:00       \n",
       "1                                               None       \n",
       "2                          2023-10-03T05:54:00-06:00       \n",
       "3                          2023-10-03T02:04:00+03:00       \n",
       "4                                               None       \n",
       "5                          2023-10-03T00:31:00+07:00       \n",
       "6                          2023-10-03T09:46:00+09:00       \n",
       "7                          2023-10-03T08:38:00+01:00       \n",
       "8                                               None       \n",
       "9                          2023-10-03T08:11:00+01:00       \n",
       "\n",
       "  data_statusDetails_departure_actualTime_outGate_utc  \\\n",
       "0                          2023-10-03T11:54:00+00:00    \n",
       "1                                               None    \n",
       "2                          2023-10-03T11:54:00+00:00    \n",
       "3                          2023-10-02T23:04:00+00:00    \n",
       "4                                               None    \n",
       "5                          2023-10-02T17:31:00+00:00    \n",
       "6                          2023-10-03T00:46:00+00:00    \n",
       "7                          2023-10-03T07:38:00+00:00    \n",
       "8                                               None    \n",
       "9                          2023-10-03T07:11:00+00:00    \n",
       "\n",
       "  data_statusDetails_departure_estimatedTime_offGround_local  \\\n",
       "0                          2023-10-03T08:15:00-04:00           \n",
       "1                                               None           \n",
       "2                                               None           \n",
       "3                                               None           \n",
       "4                                               None           \n",
       "5                                               None           \n",
       "6                                               None           \n",
       "7                                               None           \n",
       "8                                               None           \n",
       "9                                               None           \n",
       "\n",
       "  data_statusDetails_departure_estimatedTime_offGround_utc  \\\n",
       "0                          2023-10-03T12:15:00+00:00         \n",
       "1                                               None         \n",
       "2                                               None         \n",
       "3                                               None         \n",
       "4                                               None         \n",
       "5                                               None         \n",
       "6                                               None         \n",
       "7                                               None         \n",
       "8                                               None         \n",
       "9                                               None         \n",
       "\n",
       "  data_statusDetails_departure_estimatedTime_outGate_local  \\\n",
       "0                                               None         \n",
       "1                                               None         \n",
       "2                          2023-10-03T06:03:00-06:00         \n",
       "3                          2023-10-03T01:45:00+03:00         \n",
       "4                                               None         \n",
       "5                          2023-10-03T00:15:00+07:00         \n",
       "6                          2023-10-03T09:45:00+09:00         \n",
       "7                          2023-10-03T08:31:00+01:00         \n",
       "8                                               None         \n",
       "9                          2023-10-03T08:05:00+01:00         \n",
       "\n",
       "  data_statusDetails_departure_estimatedTime_outGate_utc  \n",
       "0                                               None      \n",
       "1                                               None      \n",
       "2                          2023-10-03T12:03:00+00:00      \n",
       "3                          2023-10-02T22:45:00+00:00      \n",
       "4                                               None      \n",
       "5                          2023-10-02T17:15:00+00:00      \n",
       "6                          2023-10-03T00:45:00+00:00      \n",
       "7                          2023-10-03T07:31:00+00:00      \n",
       "8                                               None      \n",
       "9                          2023-10-03T07:05:00+00:00      \n",
       "\n",
       "[10 rows x 80 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd = dftd.toPandas()\n",
    "print(pd.shape)\n",
    "pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5ace10-5ee1-45e2-b968-4d84ae02a1ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
